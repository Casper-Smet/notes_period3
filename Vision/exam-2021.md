Exam 20210407
17:29
1. I would position the chessboard in such a way that the opencv findchessboardcorners function would be able to find the chessboard corners automatically for each iPhone. If this is unfeasible, I would add the option to manually select the chess board corners. Including the distance between each corner, so I could map the pixel distances to real world coordinates. I would then use opencv's calibrate camera functions with the camera intrinsics to calculate the camera intrinsics (rotation and transformation). I would then make a 3D grid and manually adjust it so that I can have an accurate representation of the room.
For the online phase, it depends entirely on what we wish to accomplish. I'm assuming we can do backprojection using the grid from the offline phase to match pixels to voxels
**Explicitely mention MatchPNP         2-3/4**
2. 
    a. 
        1) For each frame calculate the histograms of oriented gradient
        2) Using a sliding window of size 30x80, try to match each window to any of  the 100 T_HOGs. Every sliding window that matches is then identified as a person in the foreground
        3) Back project each pixel that is identified as foreground in one of the views so it returns a list of voxels (3D coordinates)
        4) Using ProjectToView, for each view, input the list of voxels. The output should be a dictionary of pixel coordinates (2D) to voxel ids.
        5) Compare each list of pixel coordinates with the foreground masks, remove all pixel coordinates that are not in the foreground masks
        6) Take the intersection of all the remaning pixel coordinates, and using the dictionary find the voxel ids that should overlap
        7) Activate the voxels connected to the voxel ids, this is then your voxel model.
    **Decent idea of how they work, should have mentioned threshold between two HOGs
    b. Repeat the previous method, but add more views to backproject with